{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import pandas as pd\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = pymysql.connect(\n",
    "    host='192.168.10.113',\n",
    "    user='jiashengjie',\n",
    "    password='jiashengjie',\n",
    "    database='gaokao')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql('SELECT * FROM shaanxi_gaokao LIMIT 10',con=con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_c_c_dict = {value: key for key, value in c_c_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = new_df.rename(columns=lambda x:reverse_c_c_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_dtypes(x):\n",
    "    if 'int' in x:\n",
    "        return 'int'\n",
    "    elif 'float' in x:\n",
    "        return 'float'\n",
    "    else:\n",
    "        return 'str'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检测数据类型\n",
    "dtype_dict = dict(df.dtypes.astype(str).apply(format_dtypes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql('SELECT * FROM gaokao.localscore WHERE name=\"江南大学\" AND location in (\"北京\",\"天津\")',con=con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[0,'name'] = '华中科技大学'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xpinyin import Pinyin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Pinyin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取中文，转换拼音，拼接返回\n",
    "def format_string(x):\n",
    "    # 提取中文\n",
    "    ch_part = re.findall(r\"[\\u4e00-\\u9fa5]+\", x)\n",
    "    ch_part = '_'.join(ch_part)\n",
    "    if ch_part:\n",
    "        # 转成拼音\n",
    "        ch_part = p.get_pinyin(ch_part, '_').replace('___', '_')\n",
    "        # 提取首字母\n",
    "        ch_part = ''.join([py[0] for py in ch_part.split('_')])\n",
    "    # 拼接非中文字符\n",
    "    en_part = re.findall(r\"[a-zA-Z0-9]+\", x)\n",
    "    en_part = ''.join(en_part)\n",
    "\n",
    "    \n",
    "    result = en_part + '_' + ch_part if en_part and ch_part else (ch_part if ch_part else en_part)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns[1:]:\n",
    "    # str类型：英文不变，数字不变，中文转为首字符拼音\n",
    "    if df[col].dtype == 'O':\n",
    "        df[f'{col}_sort'] = df[col].apply(format_string)\n",
    "        max_len = df[f'{col}_sort'].astype(str).apply(lambda x:len(x)).max()\n",
    "        df[f'{col}_sort'] = df[f'{col}_sort'].astype(str).str.ljust(max_len,'0')\n",
    "    else:\n",
    "        max_len = df[col].astype(str).apply(lambda x:len(x)).max()\n",
    "        df[f'{col}_sort'] = df[col].astype(str).str.zfill(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['batch'].dtype == 'O'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = [file for file in os.listdir('Mini_Data_Middle_Plateform/docs/') if 'upload_file' in file][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(os.path.join('Mini_Data_Middle_Plateform/docs',filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True).reset_index().rename(columns={'index':'id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>分数</th>\n",
       "      <th>人数</th>\n",
       "      <th>累计人数</th>\n",
       "      <th>比例(%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>678</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>0.124818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>677</td>\n",
       "      <td>22</td>\n",
       "      <td>83</td>\n",
       "      <td>0.169835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>676</td>\n",
       "      <td>15</td>\n",
       "      <td>98</td>\n",
       "      <td>0.200528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>675</td>\n",
       "      <td>39</td>\n",
       "      <td>137</td>\n",
       "      <td>0.280330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>674</td>\n",
       "      <td>31</td>\n",
       "      <td>168</td>\n",
       "      <td>0.343762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   分数  人数  累计人数     比例(%)\n",
       "0   0  678  61    61  0.124818\n",
       "1   1  677  22    83  0.169835\n",
       "2   2  676  15    98  0.200528\n",
       "3   3  675  39   137  0.280330\n",
       "4   4  674  31   168  0.343762"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_str = f'CREATE TABLE {db_en} (id INT NOT NULL,'\n",
    "\n",
    "for col_name in col_names:\n",
    "    create_str += f\"{reverse_c_c_dict[col_name]} {dtype_cc_dict['for_sql'][col_dtypes[col_names.index(col_name)]]} NULL,\"\n",
    "\n",
    "create_str += 'PRIMARY KEY (id));'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute(create_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123, 5)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 上传数据\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fs': 'int', 'rs': 'str', 'ljrs': 'str', 'bl': 'float', 'id': 'int'}"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtype_dict[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'067861610.12481839945980235'"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'122,556,186,21667,44.33508624746783,'"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'INSERT INTO zkyfdb (id,fs,rs,ljrs,bl) VALUES (122,556,186,21667,44.33508624746783);'"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insert_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fdd092f082e41f69c3f9261bdf7810e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=123), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "IntegrityError",
     "evalue": "(1062, \"Duplicate entry '0' for key 'zkyfdb.PRIMARY'\")",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIntegrityError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-199-4628839e32bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0minsert_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"INSERT INTO {db_en} VALUES ({value_str[:-1]});\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mcursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minsert_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\ProgramData\\Anaconda3\\lib\\site-packages\\pymysql\\cursors.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, query, args)\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[0mquery\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmogrify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_query\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_executed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ProgramData\\Anaconda3\\lib\\site-packages\\pymysql\\cursors.py\u001b[0m in \u001b[0;36m_query\u001b[1;34m(self, q)\u001b[0m\n\u001b[0;32m    326\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_last_executed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clear_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m         \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    329\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrowcount\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ProgramData\\Anaconda3\\lib\\site-packages\\pymysql\\connections.py\u001b[0m in \u001b[0;36mquery\u001b[1;34m(self, sql, unbuffered)\u001b[0m\n\u001b[0;32m    515\u001b[0m                 \u001b[0msql\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msql\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'surrogateescape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_execute_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCOMMAND\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOM_QUERY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msql\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_affected_rows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_query_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munbuffered\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0munbuffered\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_affected_rows\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ProgramData\\Anaconda3\\lib\\site-packages\\pymysql\\connections.py\u001b[0m in \u001b[0;36m_read_query_result\u001b[1;34m(self, unbuffered)\u001b[0m\n\u001b[0;32m    730\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    731\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMySQLResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 732\u001b[1;33m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    733\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    734\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserver_status\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ProgramData\\Anaconda3\\lib\\site-packages\\pymysql\\connections.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1073\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1074\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1075\u001b[1;33m             \u001b[0mfirst_packet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_packet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1076\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1077\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mfirst_packet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_ok_packet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ProgramData\\Anaconda3\\lib\\site-packages\\pymysql\\connections.py\u001b[0m in \u001b[0;36m_read_packet\u001b[1;34m(self, packet_type)\u001b[0m\n\u001b[0;32m    682\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    683\u001b[0m         \u001b[0mpacket\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpacket_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuff\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 684\u001b[1;33m         \u001b[0mpacket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    685\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpacket\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ProgramData\\Anaconda3\\lib\\site-packages\\pymysql\\protocol.py\u001b[0m in \u001b[0;36mcheck_error\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    218\u001b[0m             \u001b[0merrno\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_uint16\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"errno =\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrno\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m             \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_mysql_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ProgramData\\Anaconda3\\lib\\site-packages\\pymysql\\err.py\u001b[0m in \u001b[0;36mraise_mysql_exception\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[0merrval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'replace'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[0merrorclass\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_map\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merrno\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mInternalError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0merrorclass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merrno\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIntegrityError\u001b[0m: (1062, \"Duplicate entry '0' for key 'zkyfdb.PRIMARY'\")"
     ]
    }
   ],
   "source": [
    "for i in tqdm_notebook(df.index):\n",
    "    value_str = ''\n",
    "    for col in df.columns:\n",
    "        value_str += f'{eval(dtype_dict[col])(df.loc[i,col])},'\n",
    "        \n",
    "    insert_str = f\"INSERT INTO {db_en} VALUES ({value_str[:-1]});\"\n",
    "    cursor.execute(insert_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'id', 'fs': '分数', 'rs': '人数', 'ljrs': '累计人数', 'bl': '比例'}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_c_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fs': 'int', 'rs': 'str', 'ljrs': 'str', 'bl': 'float', 'id': 'int'}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtype_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dc = {'a':1,'a__1':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a__2'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chongming('a',test_dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test.json','w',encoding='utf-8') as f:\n",
    "    f.write(json.dumps(dtype_dict,ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Mini_Data_Middle_Plateform/docs/database_info.json',encoding='utf-8') as f:\n",
    "    js_data_read = json.load(f)\n",
    "\n",
    "js_data_read.update(new_db_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'localscore' in js_data_read"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 首页新闻\n",
    "### 西安市教育局"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup \n",
    "import urllib\n",
    "import re\n",
    "import os\n",
    "from tqdm import tqdm_notebook\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Basic_Spyder():\n",
    "    \n",
    "    def start_scrap(self,part_url_dict,rule_func):\n",
    "        result = {}\n",
    "        for part_name, part_url in part_url_dict.items():\n",
    "            res = requests.get(part_url,headers=headers)\n",
    "            soup = BeautifulSoup(res.content, 'html.parser')            \n",
    "            item_lst = rule_func(soup)\n",
    "            result[part_name] = item_lst\n",
    "        \n",
    "        return result            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_3_ago = str(datetime.date.today() - datetime.timedelta(days=3))\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:79.0) Gecko/20100101 Firefox/79.0',\n",
    "    'Accept-Language': 'zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2',\n",
    "    'Accept-Encoding': 'gzip, deflate',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "xa_edu_url_dict = {'教育要闻': 'http://edu.xa.gov.cn/xwzx/jyyw/1.html',\n",
    "                 '通知公告': 'http://edu.xa.gov.cn/xwzx/tzgg/1.html',\n",
    "                 '区域动态': 'http://edu.xa.gov.cn/xwzx/qydt/1.html'}\n",
    "\n",
    "def xa_edu_rule(soup):\n",
    "    item_lst = []\n",
    "    for item in soup.find('div', id='content').find_all('article'):\n",
    "        item_dict = {}\n",
    "        post_date = item.find('div', class_='detail').find('span').get_text()\n",
    "        if post_date < day_3_ago:\n",
    "            break\n",
    "        title = item.find('a')['title'].replace(\n",
    "            '\\\\', '').replace('/', '').replace('\\n', '')\n",
    "        article_url = base_url + item.find('a')['href']\n",
    "        item_dict['post_date'] = post_date\n",
    "        item_dict['title'] = title\n",
    "        item_dict['article_url'] = article_url\n",
    "        item_lst.append(item_dict)\n",
    "    return item_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_spyder = Basic_Spyder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'教育要闻': [{'post_date': '2020-08-21',\n",
       "   'title': '西安市2020年城六区省级示范高中、市级特色示范高中录取工作情况通报',\n",
       "   'article_url': 'http://edu.xa.gov.cn/xwzx/jyyw/5f3f3a9bf99d65030002d1f9.html'},\n",
       "  {'post_date': '2020-08-18',\n",
       "   'title': '西安市教育局办公室关于印发《西安市教育系统节约粮食杜绝浪费工作方案》的通知',\n",
       "   'article_url': 'http://edu.xa.gov.cn/xwzx/jyyw/5f3bc29c65cbd82d5b5da7aa.html'}],\n",
       " '通知公告': [{'post_date': '2020-08-21',\n",
       "   'title': '西安市2020年城六区省级示范高中、市级特色示范高中录取工作情况通报',\n",
       "   'article_url': 'http://edu.xa.gov.cn/xwzx/tzgg/5f3f3a9bf99d65030002d1f9.html'},\n",
       "  {'post_date': '2020-08-20',\n",
       "   'title': '西安市教育局关于公布2020年上半年教师资格认定结果及证书发放的公告',\n",
       "   'article_url': 'http://edu.xa.gov.cn/xwzx/tzgg/5f3e41befd850845e6db6941.html'},\n",
       "  {'post_date': '2020-08-18',\n",
       "   'title': '西安市教育局办公室关于印发《西安市教育系统节约粮食杜绝浪费工作方案》的通知',\n",
       "   'article_url': 'http://edu.xa.gov.cn/xwzx/tzgg/5f3bc29c65cbd82d5b5da7aa.html'}],\n",
       " '区域动态': [{'post_date': '2020-08-19',\n",
       "   'title': '迎十四运 创文明城——阎良教育在行动',\n",
       "   'article_url': 'http://edu.xa.gov.cn/xwzx/qydt/5f3cf1a565cbd82d5b5f2d77.html'}]}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_spyder.start_scrap(xa_edu_url_dict,xa_edu_rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'西安市教育局': {'homepage': 'http://edu.xa.gov.cn/',\n",
       "  'favicon': 'http://edu.xa.gov.cn/images/favicon.ico',\n",
       "  'result': {'教育要闻': [{'post_date': '2020-08-21',\n",
       "     'title': '西安市2020年城六区省级示范高中、市级特色示范高中录取工作情况通报',\n",
       "     'article_url': 'http://edu.xa.gov.cn/xwzx/jyyw/5f3f3a9bf99d65030002d1f9.html'},\n",
       "    {'post_date': '2020-08-18',\n",
       "     'title': '西安市教育局办公室关于印发《西安市教育系统节约粮食杜绝浪费工作方案》的通知',\n",
       "     'article_url': 'http://edu.xa.gov.cn/xwzx/jyyw/5f3bc29c65cbd82d5b5da7aa.html'}],\n",
       "   '通知公告': [{'post_date': '2020-08-21',\n",
       "     'title': '西安市2020年城六区省级示范高中、市级特色示范高中录取工作情况通报',\n",
       "     'article_url': 'http://edu.xa.gov.cn/xwzx/tzgg/5f3f3a9bf99d65030002d1f9.html'},\n",
       "    {'post_date': '2020-08-20',\n",
       "     'title': '西安市教育局关于公布2020年上半年教师资格认定结果及证书发放的公告',\n",
       "     'article_url': 'http://edu.xa.gov.cn/xwzx/tzgg/5f3e41befd850845e6db6941.html'},\n",
       "    {'post_date': '2020-08-18',\n",
       "     'title': '西安市教育局办公室关于印发《西安市教育系统节约粮食杜绝浪费工作方案》的通知',\n",
       "     'article_url': 'http://edu.xa.gov.cn/xwzx/tzgg/5f3bc29c65cbd82d5b5da7aa.html'}],\n",
       "   '区域动态': [{'post_date': '2020-08-19',\n",
       "     'title': '迎十四运 创文明城——阎良教育在行动',\n",
       "     'article_url': 'http://edu.xa.gov.cn/xwzx/qydt/5f3cf1a565cbd82d5b5f2d77.html'}]}}}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# json组织形式\n",
    "{\n",
    "}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 省教育厅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sjyt_rule(soup):\n",
    "    item_lst = []\n",
    "    for item in soup.find('div',class_='catlist').find_all('li',class_='catlist_li'):\n",
    "        item_dict = {}\n",
    "        #date\n",
    "        post_date = item.find('span').get_text()    \n",
    "        if post_date < day_3_ago:\n",
    "            break\n",
    "        title = item.find('a').get_text()\n",
    "        article_url = item.find('a')['href']\n",
    "        \n",
    "        item_dict['post_date'] = post_date\n",
    "        item_dict['title'] = title\n",
    "        item_dict['article_url'] = article_url\n",
    "        \n",
    "        item_lst.append(item_dict)\n",
    "    return item_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "sjyt_url_dict = {'公示公告': 'http://jyt.shaanxi.gov.cn/news/gsgg/',\n",
    "                 '教育厅文件': 'http://jyt.shaanxi.gov.cn/news/jiaoyutingwenjian/'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'公示公告': [],\n",
       " '教育厅文件': [{'post_date': '2020-08-19',\n",
       "   'title': '陕西省教育厅办公室关于开展2020年全省学生“学宪法 讲宪法”活动的通知',\n",
       "   'article_url': 'http://jyt.shaanxi.gov.cn/news/jiaoyutingwenjian/202008/19/17428.html'},\n",
       "  {'post_date': '2020-08-18',\n",
       "   'title': '陕西省教育厅办公室关于进一步做好普通高等教育2020年秋季学期教学工作的通知',\n",
       "   'article_url': 'http://jyt.shaanxi.gov.cn/news/jiaoyutingwenjian/202008/18/17427.html'},\n",
       "  {'post_date': '2020-08-18',\n",
       "   'title': '陕西省教育厅关于公布2020年度陕西高校青年创新团队入选名单的通知',\n",
       "   'article_url': 'http://jyt.shaanxi.gov.cn/news/jiaoyutingwenjian/202008/18/17426.html'}]}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_spyder.start_scrap(sjyt_url_dict,sjyt_rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 陕西招生考试信息网"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'陕西招生考试信息网': {'homepage': 'https://www.sneac.com/',\n",
       "  'favicon': 'https://www.sneac.com/images/bitbug_favicon.ico'}}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "szw_url_dict = {\n",
    "    '新闻公告':'http://www.sneac.com/index/xwgg1.htm',\n",
    "    '普通高考':'http://www.sneac.com/zkyw/ptgk.htm',\n",
    "    '高中学业水平考试':'http://www.sneac.com/zkyw/gzxyspks.htm',\n",
    "    '中考':'http://www.sneac.com/zkyw/zk.htm'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def szw_rule(soup):\n",
    "    item_lst = []\n",
    "    for item in soup.find('div',class_='list-box').find_all('li'):\n",
    "        item_dict = {}\n",
    "        post_date = item.find('span').get_text().replace('/','-')\n",
    "        if post_date < day_3_ago:\n",
    "            break\n",
    "        title = item.find('a').get_text()\n",
    "        article_url = base_url + item.find('a')['href'][2:]\n",
    "        \n",
    "        item_dict['post_date'] = post_date\n",
    "        item_dict['title'] = title\n",
    "        item_dict['article_url'] = article_url\n",
    "        \n",
    "        item_lst.append(item_dict)\n",
    "    return item_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "szw_result = basic_spyder.start_scrap(szw_url_dict,szw_rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'新闻公告': [{'post_date': '2020-08-21',\n",
       "   'title': '2020年陕西省普通高校招生提前批次艺术类专科A段录取征集志愿',\n",
       "   'article_url': 'http://edu.xa.gov.cn/info/1024/6893.htm'},\n",
       "  {'post_date': '2020-08-20',\n",
       "   'title': '2020年陕西省普通高校招生提前批次体育类专科录取征集志愿',\n",
       "   'article_url': 'http://edu.xa.gov.cn/info/1024/6892.htm'},\n",
       "  {'post_date': '2020-08-18',\n",
       "   'title': '2020年陕西省普通高校招生本科一批录取模拟投档信息将陆续公布',\n",
       "   'article_url': 'http://edu.xa.gov.cn/info/1024/6889.htm'},\n",
       "  {'post_date': '2020-08-18',\n",
       "   'title': '2020年陕西省普通高等学校招生单设本科批次B段(地方专项计划)投档情况统计表',\n",
       "   'article_url': 'http://edu.xa.gov.cn/info/1024/6891.htm'},\n",
       "  {'post_date': '2020-08-18',\n",
       "   'title': '2020陕西省普通高等学校招生单设本科批次B段(地方专项计划)征集投档情况统计表',\n",
       "   'article_url': 'http://edu.xa.gov.cn/info/1024/6890.htm'},\n",
       "  {'post_date': '2020-08-18',\n",
       "   'title': '2020年陕西省普通高校招生单设本科批次B段地方专项计划录取开始征集志愿',\n",
       "   'article_url': 'http://edu.xa.gov.cn/info/1024/6888.htm'},\n",
       "  {'post_date': '2020-08-18',\n",
       "   'title': '2020年陕西省普通高等学校招生单设本科批次A段(国家专项计划)征集投档情况统计表',\n",
       "   'article_url': 'http://edu.xa.gov.cn/info/1024/6887.htm'}]}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{key:value for key,value in szw_result.items() if len(value)>1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 华商报"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "huashangbao_url = 'http://edu.hsw.cn/'\n",
    "response = requests.get(huashangbao_url)\n",
    "\n",
    "soup = BeautifulSoup(response.content,'lxml')\n",
    "\n",
    "hot = soup.find('div',class_='list fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "huashang_result = []\n",
    "for item in hot.find_all('a'):\n",
    "    item_dict = {}\n",
    "    media_name = '华商报'\n",
    "    article_url = item['href']\n",
    "    article_soup = BeautifulSoup(requests.get(article_url).content,'lxml')\n",
    "    title = article_soup.find('h1').get_text()\n",
    "    post_date = article_soup.find('span',class_='article-time').get_text().split(' ')[0]\n",
    "    \n",
    "    item_dict['post_date'] = post_date\n",
    "    item_dict['title'] = title\n",
    "    item_dict['article_url'] = article_url\n",
    "    huashang_result.append(item_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'华商报教育': {'homepage': 'http://edu.hsw.cn/',\n",
       "  'favicon': 'http://static.hsw.cn/b/assets/i/favicon.png',\n",
       "  'result': {'今日推荐': [{'post_date': '2020-08-20',\n",
       "     'title': '辞去大学教师工作 80后女孩甘当孩子“梦想守护神”',\n",
       "     'article_url': 'http://edu.hsw.cn/system/2020/0820/134430.shtml'},\n",
       "    {'post_date': '2020-08-20',\n",
       "     'title': '武汉部分高校发布返校通知：强化封闭管理',\n",
       "     'article_url': 'http://edu.hsw.cn/system/2020/0820/134429.shtml'},\n",
       "    {'post_date': '2020-08-19',\n",
       "     'title': '向前，以青春的勇气',\n",
       "     'article_url': 'http://edu.hsw.cn/system/2020/0819/134412.shtml'}]}}}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "    \"华商报教育\": {\n",
    "        \"homepage\": \"http://edu.hsw.cn/\",\n",
    "        \"favicon\": \"http://static.hsw.cn/b/assets/i/favicon.png\",\n",
    "        \"result\": {'今日推荐':huashang_result}}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 新浪教育"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "xinlang_url = 'http://edu.sina.com.cn/'\n",
    "response = requests.get(xinlang_url)\n",
    "\n",
    "soup = BeautifulSoup(response.content,'lxml')\n",
    "\n",
    "rank_news = soup.find('div',class_='rank_news').find_all('a')\n",
    "rank_commt = soup.find('div',class_='rank_commt').find_all('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_date(date):\n",
    "    year = date.split('年')[0]\n",
    "    month = date.split('年')[1].split('月')[0]\n",
    "    day = date.split('年')[1].split('月')[1].split('日')[0]\n",
    "    return (f'{year}-{month}-{day}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title_date(article_url):\n",
    "    article_soup = BeautifulSoup(requests.get(article_url).content,'lxml')\n",
    "    try:\n",
    "        title = article_soup.find('h1').get_text()\n",
    "        date = format_date(article_soup.find('span',class_='date').get_text())\n",
    "    except:\n",
    "        title = article_soup.find('meta',attrs={'property':\"og:title\"})['content']\n",
    "        date = article_soup.find('meta',attrs={'property':\"article:published_time\"})['content'].split('T')[0]\n",
    "    return (title,date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['新闻排行'] = []\n",
    "for item in rank_news:\n",
    "    item_dict = {}\n",
    "    article_url = item['href']\n",
    "    title,post_date = get_title_date(article_url)\n",
    "    item_dict['post_date'] = post_date\n",
    "    item_dict['title'] = title\n",
    "    item_dict['article_url'] = article_url\n",
    "    result['新闻排行'].append(item_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['评论排行'] = []\n",
    "for item in rank_commt:\n",
    "    item_dict = {}\n",
    "    article_url = item['href']\n",
    "    title,post_date = get_title_date(article_url)\n",
    "    item_dict['post_date'] = post_date\n",
    "    item_dict['title'] = title\n",
    "    item_dict['article_url'] = article_url\n",
    "    result['评论排行'].append(item_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 知乎"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get('https://www.zhihu.com/hot',headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(res.content,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'accept-language': 'zh-CN,zh;q=0.9',\n",
    "    'origin': 'https://www.zhihu.com',\n",
    "    'referer': 'https://www.zhihu.com/question/290268306',\n",
    "    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3497.100 Safari/537.36'\n",
    "}\n",
    "\n",
    "\n",
    "def extract_data(item):\n",
    "    \n",
    "    #id\n",
    "    item_id = item['id']\n",
    "    # 问题相关\n",
    "    question = item['target'].get('question')\n",
    "    \n",
    "    if question:\n",
    "        # 问题标题\n",
    "        question_title = question['title']\n",
    "        # 问题内容\n",
    "        question_excerpt = question['excerpt']\n",
    "        # 问题回答数量\n",
    "        answer_count = question['answer_count']\n",
    "        # 问题评论数量\n",
    "        comment_count = question['comment_count']\n",
    "        # 问题关注量\n",
    "        follower_count = question['follower_count']\n",
    "        # 问题链接\n",
    "        question_url = question['url']\n",
    "        # 提问人昵称\n",
    "        question_author = question['author']['name']\n",
    "        # 提问人主页\n",
    "        question_author_url = question['author']['url']\n",
    "        # 提问时间\n",
    "        question_timestamp = question['created']\n",
    "    else:\n",
    "        question_title = item['target']['title'] if item['target'].get('title') else ''\n",
    "        question_excerpt = ''\n",
    "        answer_count = ''\n",
    "        comment_count = ''\n",
    "        follower_count = ''\n",
    "        question_url = item['target']['url'] if item['target'].get('url') else ''\n",
    "        question_author = ''\n",
    "        question_author_url = ''\n",
    "        question_timestamp = ''\n",
    "    # 回答相关\n",
    "    # 回答时间\n",
    "    answer_created_time = item['created_time']\n",
    "    #回答更新时间\n",
    "    answer_updated_time = item['target'].get('updated_time','')\n",
    "    #回答内容\n",
    "    answer_content = item['target'].get('content','')\n",
    "    #赞同数量\n",
    "    answer_voteup_count = item['target'].get('voteup_count','')\n",
    "    #评论量\n",
    "    answer_comment_count = item['target'].get('comment_count','')\n",
    "    #喜欢量\n",
    "    answer_thanks_count = item['target'].get('thanks_count','')\n",
    "    # 回答作者\n",
    "    answer_author = item['target']['author']['name'] if item['target'].get('author') else ''\n",
    "    answer_author_url = item['target']['author']['url'] if item['target'].get('author') else ''\n",
    "    # 回答or收藏\n",
    "    action_text = item['action_text']\n",
    "    \n",
    "    df = pd.DataFrame(columns=['id','问题标题','问题内容','回答数量','问题评论量','问题关注量','问题链接','提问者昵称','提问者主页','提问时间',\n",
    "                              '回答时间','回答更新时间','回答内容','赞同量','评论量','喜欢量','回答作者','回答作者主页','行为类型'])\n",
    "    \n",
    "    df.loc[df.shape[0]] = (item_id,question_title,question_excerpt,answer_count,comment_count,follower_count,question_url,question_author,\n",
    "                           question_author_url,question_timestamp, answer_created_time,answer_updated_time,answer_content,\n",
    "                           answer_voteup_count,answer_comment_count,answer_thanks_count,answer_author,answer_author_url,action_text)    \n",
    "    \n",
    "    return df\n",
    "\n",
    "def scrap_user_activities(start_url):\n",
    "\n",
    "    limit_per_page = int(re.findall(r'limit=(\\d+)',start_url)[0])\n",
    "    # 设置MAX COUNT，至多获取最近一万条数据\n",
    "    MAX_COUNT = int(10000 / limit_per_page)\n",
    "\n",
    "    # 初始化\n",
    "    if os.path.exists(f'./docs/zhihu_user_activities.csv'):\n",
    "        all_df = pd.read_csv(f'./docs/zhihu_user_activities.csv')\n",
    "\n",
    "        with open(f'./docs/zhihu_user_activities_urls.txt') as f:\n",
    "            next_url_lst = eval(f.read())\n",
    "\n",
    "        count = int(all_df.shape[0] / limit_per_page)\n",
    "    else:\n",
    "        all_df = pd.DataFrame()\n",
    "        next_url_lst = [start_url]\n",
    "        count = 0\n",
    "    \n",
    "    \n",
    "\n",
    "    flag = False\n",
    "    \n",
    "    print('Scraping...')\n",
    "    \n",
    "    while count <= MAX_COUNT:\n",
    "    #     if not os.path.exists(f'laoyang_zhihu/{count}.csv'):\n",
    "        if count % 50 == 0:\n",
    "            print(f'Page {count+1} is scraping...')\n",
    "\n",
    "        res = requests.get(next_url_lst[-1],headers=headers)\n",
    "        data = res.json()\n",
    "\n",
    "        #最后一页了吗？\n",
    "        flag = data['paging']['is_end']\n",
    "        if flag:\n",
    "            yield(count,count)\n",
    "            break\n",
    "\n",
    "        #下一页url\n",
    "        next_url_lst.append(data['paging']['next'])\n",
    "        # item_lst\n",
    "        item_lst = data['data']\n",
    "        # 保存数据\n",
    "        df = pd.DataFrame()\n",
    "        for item in item_lst:\n",
    "            tmp = extract_data(item)\n",
    "            df = df.append(tmp)\n",
    "        \n",
    "        all_df = all_df.append(df)\n",
    "        \n",
    "        all_df.to_csv(f'./docs/zhihu_user_activities.csv',index=False)\n",
    "        \n",
    "        with open(f'./docs/zhihu_user_activities_urls.txt','w') as f:\n",
    "            f.write(str(next_url_lst))\n",
    "\n",
    "        count += 1\n",
    "        time.sleep(random.randint(2,4))\n",
    "        yield(MAX_COUNT,count)\n",
    "\n",
    "def scrap_user_videos(user_name,user_url):\n",
    "    urlToken = user_url.split('/')[-1]\n",
    "    # 检验是否有视频\n",
    "    res = requests.get(user_url,headers=headers)\n",
    "    soup = BeautifulSoup(res.content,'html.parser')\n",
    "    try:\n",
    "        video_num = soup.find('div',class_='ProfileMain-header').find_all('a')[2].find('span').get_text()\n",
    "    except IndexError:\n",
    "        print(user_url)\n",
    "    video_num = int(video_num)\n",
    "    \n",
    "    columns = ['用户名称','urlToken','视频id','标题','封面','描述','时长（s）',\n",
    "               '高清链接','发布时间','播放量','评论量','点赞量','视频页链接']\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    \n",
    "    if video_num > 0:\n",
    "        print('Scraping Homepage Videos...')\n",
    "        # 先爬取主页的video\n",
    "        video_url = user_url + '/zvideos'\n",
    "        res = requests.get(video_url,headers=headers)\n",
    "        soup = BeautifulSoup(res.content,'html.parser')\n",
    "        \n",
    "        script = soup.find('script',id='js-initialData').get_text()\n",
    "        script = eval(script.replace('false','False').replace('true','True').replace('null','None'))\n",
    "        video_items = script['initialState']['entities']['zvideos']\n",
    "        video_items = list(video_items.values())\n",
    "        \n",
    "        for item in video_items:\n",
    "            video_id = item['id']\n",
    "            # 视频标题\n",
    "            video_title = item['title']\n",
    "            # 封面\n",
    "            video_imageUrl = item['imageUrl']\n",
    "            # 描述\n",
    "            video_description = item['description']\n",
    "            # 视频时长 单位：s\n",
    "            video_duration = item['video']['duration']\n",
    "            # 视频高清链接\n",
    "            highest_hd = list(item['video']['playlist'].keys())[0]\n",
    "            video_playUrl = item['video']['playlist'][highest_hd]['playUrl']\n",
    "            # 发布时间\n",
    "            video_publishedAt = item['publishedAt']\n",
    "            # 播放量,评论，点赞\n",
    "            video_playCount,video_commentCount,video_voteupCount = item['playCount'],item['commentCount'],item['voteupCount']\n",
    "            # 视频页链接\n",
    "            video_page_url = item['url'].replace('api/v4/zvideos','zvideo')\n",
    "            \n",
    "            df.loc[df.shape[0]] = (user_name,urlToken,video_id,video_title,video_imageUrl,video_description,\n",
    "                                   video_duration,video_playUrl,video_publishedAt,video_playCount,video_commentCount,\n",
    "                                   video_voteupCount,video_page_url)\n",
    "            \n",
    "            \n",
    "        \n",
    "        if len(video_items) < video_num:\n",
    "            print('Scraping More Videos Through API...')\n",
    "            # 构造api，爬取更多\n",
    "            video_api = f'https://www.zhihu.com/api/v4/members/{urlToken}/zvideos?offset={len(video_items)}&limit=10'\n",
    "            next_lst = [video_api]\n",
    "            \n",
    "            is_end = False\n",
    "            while not is_end:\n",
    "                res = requests.get(next_lst[-1],headers=headers)\n",
    "                res_json = res.json()            \n",
    "                \n",
    "                for item in res_json['data']:\n",
    "                    try:\n",
    "                        highest_hd = list(item['video']['playlist'].keys())[0]\n",
    "                    except KeyError:\n",
    "                        print(user_url)\n",
    "                        return\n",
    "                    df.loc[df.shape[0]] = (user_name,urlToken,item['id'],item['title'],item['image_url'],item['description'],\n",
    "                                           item['video']['duration'],item['video']['playlist'][highest_hd]['play_url'],\n",
    "                                           item['published_at'],item['play_count'],item['comment_count'],item['voteup_count'],\n",
    "                                           item['url'].replace('api/v4/zvideos','zvideo'))\n",
    "                \n",
    "                \n",
    "                # 下一页链接\n",
    "                next_lst.append(res_json['paging']['next'])\n",
    "                # 最后一页吗\n",
    "                is_end = res_json['paging']['is_end']\n",
    "    \n",
    "    if len(df) > 0:\n",
    "        df.to_csv(f'./docs/zhihu_user_activities_videos.csv')\n",
    "\n",
    "def get_user_details(homepage):\n",
    "    \n",
    "    def test_dict(dic,key):\n",
    "        return item[key]['name'] if item.get(key) else ''\n",
    "    \n",
    "    urlToken = homepage.split('/')[-1]\n",
    "    res = r.get(homepage,headers=headers)\n",
    "    soup = BeautifulSoup(res.content,'html.parser')\n",
    "    # 首图.\n",
    "    try:\n",
    "        headpic = soup.find('div',class_='Card').find('div',class_='UserCover').find('div')['data-src']\n",
    "    except:\n",
    "        headpic = ''\n",
    "    \n",
    "    script = soup.find('script',id='js-initialData').get_text()\n",
    "    script = eval(script.replace('false','False').replace('true','True').replace('null','None'))\n",
    "    \n",
    "    # start url\n",
    "    start_url = script['initialState']['people']['activitiesByUser'][urlToken]['previous']\n",
    "    \n",
    "    user_info = script['initialState']['entities']['users'][urlToken]\n",
    "    # 头像\n",
    "    avatar = user_info['avatarUrl']\n",
    "    name = user_info['name']\n",
    "    headline = user_info['headline']\n",
    "    # 个人简介\n",
    "    description = user_info['description']\n",
    "    # VIP\n",
    "    is_VIP = user_info['vipInfo']['isVip']\n",
    "    # 认证情况\n",
    "    badges = []\n",
    "    for item in user_info['badgeV2']['detailBadges']:\n",
    "        badges.append('{}_{}'.format(item['title'] if item.get('title') else '',item['description'] if item.get('description') else ''))\n",
    "    \n",
    "    \n",
    "    followerCount,followingCount,mutualFolloweesCount,answerCount,questionCount = user_info['followerCount'],user_info['followingCount'],user_info['mutualFolloweesCount'],user_info['answerCount'],user_info['questionCount']\n",
    "    articlesCount,columnsCount,zvideoCount,favoritedCount,voteupCount,thankedCount = user_info['articlesCount'],user_info['columnsCount'],user_info['zvideoCount'],user_info['favoritedCount'], user_info['voteupCount'],user_info['thankedCount'],\n",
    "    \n",
    "    # 所在行业\n",
    "    business = user_info['business']['name']\n",
    "    \n",
    "    # 居住地\n",
    "    locations = []\n",
    "    for item in user_info['locations']:\n",
    "        locations.append(item['name'])\n",
    "        \n",
    "    # 职业经历\n",
    "    employments = []\n",
    "    for item in user_info['employments']:\n",
    "        employments.append('{}_{}'.format(test_dict(item,'company'),test_dict(item,'job')))\n",
    "        \n",
    "    # 教育经历\n",
    "    educations = []\n",
    "    for item in user_info['educations']:\n",
    "        educations.append('{}_{}'.format(test_dict(item,'school'),test_dict(item,'major')))\n",
    "    \n",
    "    columns = ['昵称','主页','首图','头像','头条','个人简介','所在行业','居住地','职业经历','教育经历','是否开通VIP','认证情况',\n",
    "               '粉丝人数','关注人数','互关人数','回答数','提问数',\n",
    "              '文章数','专栏数','视频数','被收藏数','获赞数','被喜欢数','start_url']\n",
    "    \n",
    "    user_info_data = pd.DataFrame(columns=columns)\n",
    "    user_info_data.loc[0] = (name,homepage,headpic,avatar,headline,description,business,str(locations),str(employments),str(educations),\n",
    "                             is_VIP,str(badges),followerCount,followingCount,mutualFolloweesCount,answerCount,questionCount,\n",
    "                             articlesCount,columnsCount,zvideoCount,favoritedCount,voteupCount,thankedCount,start_url)\n",
    "\n",
    "    user_info_data.to_excel('./docs/zhihu_user_info.xlsx',encoding='utf-8-sig',index=False)\n",
    "\n",
    "    return user_info_data    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
